{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a0d5b62-0355-4ab8-b76d-fbcb638a0388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "818716ec-3447-43c6-ac95-b364323b9162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "[2026-02-14 11:36:34] INFO modeling.py:987: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc4f97076924605b6721eb6225bb0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded without dynamic module writing\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_PATH = \"/workspace/AAIPL/hf_models/huggingface/models--microsoft--Phi-4-mini-instruct/snapshots/cfbefacb99257ffa30c83adab238a50856ac3083\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=False,  # ðŸ”¥ Important\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=False,  # ðŸ”¥ Important\n",
    ")\n",
    "\n",
    "print(\"âœ… Loaded without dynamic module writing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9de8737d-045c-456e-9e38-904750bc0782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,145,728 || all params: 3,839,167,488 || trainable%: 0.0819\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b78b3b3e-3d71-4ec4-bd0b-342c282a9fb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a difficult question about reinforcement learning. Your response must have 3 sections. Mark the beginning of each section with SECTION X, such as: SECTION 1. The word \"agent\" should appear at least 5 times. SECTION 1\n",
      "\n",
      "In the context of reinforcement learning, consider\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    \"Generate a difficult question about reinforcement learning.\",\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50\n",
    "    )\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff77437e-3b88-4438-88e9-a4932ec9bd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl) (4.3.0)\n",
      "Requirement already satisfied: transformers>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from trl) (4.56.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (7.1.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0a0+git1c57644)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.9.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=3.0.0->trl) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (79.0.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (2025.10.23)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (0.22.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets>=3.0.0->trl) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.12 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install trl accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9acdc9e-25ce-4c03-b086-b4aa5b785eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model.config.use_cache = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b466cebf-a8c8-4da8-9d1b-9b73b04836d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "\n",
    "def reward_function(samples):\n",
    "    rewards = []\n",
    "    \n",
    "    for text in samples:\n",
    "        reward = 0\n",
    "        \n",
    "        # Reward if ends with question mark\n",
    "        if text.strip().endswith(\"?\"):\n",
    "            reward += 1.0\n",
    "        \n",
    "        # Penalize if contains explanation words\n",
    "        if \"because\" in text.lower():\n",
    "            reward -= 0.5\n",
    "        \n",
    "        # Penalize formatting\n",
    "        if \"SECTION\" in text:\n",
    "            reward -= 1.0\n",
    "        \n",
    "        # Reward length window\n",
    "        token_count = len(text.split())\n",
    "        if 15 <= token_count <= 40:\n",
    "            reward += 1.0\n",
    "        \n",
    "        # Reward advanced terms\n",
    "        advanced_terms = [\"convergence\", \"approximation\", \"instability\", \n",
    "                          \"divergence\", \"stochastic\", \"policy gradient\"]\n",
    "        \n",
    "        for term in advanced_terms:\n",
    "            if term in text.lower():\n",
    "                reward += 0.5\n",
    "        \n",
    "        rewards.append(reward)\n",
    "    \n",
    "    return torch.tensor(rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ebf09b-ee2d-4702-9071-a1c567527e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c82e2455-b9eb-4413-a433-55b25087667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from typing import List\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "MODEL_PATH = \"/workspace/AAIPL/hf_models/Meta-Llama-3.1-8B-Instruct\"\n",
    "OUTPUT_FILE = \"generated_reasoning_dataset.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "44c68e68-a69c-447c-a951-89b7501095ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPACA_PROMPT = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3cab191-f197-4c51-8fc5-9d548a03af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent:\n",
    "    def __init__(self, max_seq_length=4096):\n",
    "        dtype = None\n",
    "        load_in_4bit = False\n",
    "\n",
    "        self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
    "            model_name=MODEL_PATH,\n",
    "            max_seq_length=max_seq_length,\n",
    "            dtype=dtype,\n",
    "            load_in_4bit=load_in_4bit,\n",
    "            device_map=\"cuda\",\n",
    "        )\n",
    "\n",
    "        FastLanguageModel.for_inference(self.model)\n",
    "        print(\"âœ… QAgent model loaded\")\n",
    "\n",
    "    def generate(self, instruction: str, max_new_tokens=800):\n",
    "        prompt = ALPACA_PROMPT.format(instruction, \"\")\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.9,\n",
    "            top_p=0.95,\n",
    "            do_sample=True,\n",
    "            use_cache=True,\n",
    "        )\n",
    "\n",
    "        generated_ids = outputs[0][len(inputs.input_ids[0]):]\n",
    "        return self.tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33929d5b-0512-49c0-8f2c-a98a7b87b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATION_INSTRUCTION = \"\"\"\n",
    "Generate one difficult logical reasoning MCQ.\n",
    "\n",
    "Allowed topics:\n",
    "- Syllogism\n",
    "- Seating Arrangement (Circular or Linear, no permutation counting)\n",
    "- Blood Relations\n",
    "- Mixed Alphanumeric Series\n",
    "\n",
    "Return ONLY valid JSON in this exact format:\n",
    "\n",
    "{\n",
    "    \"topic\": \"One of the allowed topics\",\n",
    "    \"question\": \"Full question ending with a question mark?\",\n",
    "    \"choices\": [\n",
    "        \"A) ...\",\n",
    "        \"B) ...\",\n",
    "        \"C) ...\",\n",
    "        \"D) ...\"\n",
    "    ],\n",
    "    \"answer\": \"A/B/C/D\",\n",
    "    \"explanation\": \"Brief explanation\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Must require multi-step reasoning\n",
    "- Only one correct answer\n",
    "- No ambiguity\n",
    "- No extra commentary outside JSON\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f6f5cc8-4a68-4342-9a93-52aac5b16cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(text):\n",
    "    try:\n",
    "        json_match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "        if json_match:\n",
    "            return json.loads(json_match.group())\n",
    "    except:\n",
    "        return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14c02ce2-ba1a-4d08-a158-1b73be4d15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n_samples=100):\n",
    "    model = QAgent()\n",
    "    dataset = []\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        try:\n",
    "            response = model.generate(GENERATION_INSTRUCTION)\n",
    "            data = extract_json(response)\n",
    "\n",
    "            if data:\n",
    "                dataset.append(data)\n",
    "                print(f\"âœ… {i+1}/{n_samples} generated\")\n",
    "            else:\n",
    "                print(f\"âŒ Invalid JSON at {i+1}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš  Error at {i+1}: {e}\")\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c0a76a0-d231-40a5-ae88-dc74413d44d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(dataset, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for item in dataset:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "    print(f\"ðŸ’¾ Saved {len(dataset)} samples to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b201aa9-7b5e-491f-a938-fb6a535e2ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/AAIPL/hf_models/huggingface/models--microsoft--Phi-4-mini-instruct/snapshots/cfbefacb99257ffa30c83adab238a50856ac3083\n",
      "/workspace/AAIPL/hf_models/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/snapshots/4699cc75b550f9c6f3173fb80f4703b62d946aa5\n",
      "/workspace/AAIPL/hf_models/huggingface/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/c170c708c41dac9275d15a8fff4eca08d52bab71\n",
      "/workspace/AAIPL/hf_models/huggingface/models--unsloth--gpt-oss-20b-BF16/snapshots/cc89b3e7fd423253264883a80a4fa5abc619649f\n",
      "/workspace/AAIPL/hf_models/huggingface/models--google--gemma-3-12b-it/snapshots/96b6f1eccf38110c56df3a15bffe176da04bfd80\n",
      "/workspace/AAIPL/hf_models/huggingface/models--Qwen--Qwen2.5-14B-Instruct/snapshots/cf98f3b3bbb457ad9e2bb7baf9a0125b6b88caa8\n",
      "/workspace/AAIPL/hf_models/huggingface/models--Qwen--Qwen3-4B/snapshots/1cfa9a7208912126459214e8b04321603b3df60c\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"/workspace/AAIPL/hf_models\"):\n",
    "    if \"config.json\" in files:\n",
    "        print(root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93a313d9-b495-4ecd-9a16-649b7a6bc6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "MODEL_PATH = \"/workspace/AAIPL/hf_models/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/snapshots/4699cc75b550f9c6f3173fb80f4703b62d946aa5\"\n",
    "\n",
    "class QAgent:\n",
    "    def __init__(self, max_seq_length=4096):\n",
    "        dtype = torch.bfloat16  # AMD safe\n",
    "        load_in_4bit = False\n",
    "\n",
    "        self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
    "            model_name=MODEL_PATH,\n",
    "            max_seq_length=max_seq_length,\n",
    "            dtype=dtype,\n",
    "            load_in_4bit=load_in_4bit,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "        FastLanguageModel.for_inference(self.model)\n",
    "        print(\"âœ… QAgent loaded successfully\")\n",
    "\n",
    "    def generate(self, instruction, max_new_tokens=800):\n",
    "        prompt = f\"\"\"Below is an instruction.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.9,\n",
    "            top_p=0.95,\n",
    "            do_sample=True,\n",
    "            use_cache=True,\n",
    "        )\n",
    "\n",
    "        generated_ids = outputs[0][len(inputs.input_ids[0]):]\n",
    "        return self.tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2e34aa8-d866-4f53-b0f1-2f49dc057b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-14 12:03:46] INFO modeling.py:987: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: AMD currently is not stable with 4bit bitsandbytes. Disabling for now.\n",
      "==((====))==  Unsloth 2025.10.9: Fast Llama patching. Transformers: 4.56.2. vLLM: 0.11.1rc3.dev39+gf417746ad.rocm700.\n",
      "   \\\\   /|    . Num GPUs = 1. Max memory: 255.688 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0a0+git1c57644. ROCm Toolkit: 7.0.51831-a3e329ad8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd79a5069de4164afdf4e816e8e37cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… QAgent loaded successfully\n",
      "Here is a difficult syllogism MCQ in valid JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"question\": \"All humans are mortal. Socrates is human. Therefore, Socrates is mortal. Which of the following is a valid conclusion?\",\n",
      "  \"options\": [\n",
      "    {\n",
      "      \"text\": \"All humans are mortal, so Socrates is mortal\",\n",
      "      \"correct\": false\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Socrates is a human, so he is definitely mortal\",\n",
      "      \"correct\": false\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Socrates is mortal because all humans are mortal\",\n",
      "      \"correct\": true\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Humans are mortal only if Socrates is too\",\n",
      "      \"correct\": false\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "This MCQ presents a syllogism based on the principle of universal instantiation, which is a valid logical argument. The correct answer is a straightforward application of this principle. The other options either rephrase the premises without logically connecting them, or make unfounded assumptions, which are characteristic of invalid syllogisms. This type of question requires critical thinking and an understanding of logical principles to arrive at the correct answer.  A good candidate should be able to break down the question into its components, identify the relevant logical principles, and apply them correctly to choose the correct answer. This question assesses not only their knowledge of logic but also their ability to reason and think critically.   The correct answer is \"Socrates is mortal because all humans are mortal\". This is a valid conclusion because it correctly applies the principle of universal instantiation, which states that if all members of a class have a certain property, then any individual member of that class also has that property. Here, the class is \"humans\" and the property is \"mortality\", and Socrates is an individual member of that class. Therefore, since all humans are mortal, Socrates, being a human, is also mortal.   The other options are incorrect because they either simply rephrase the premises without drawing a logical conclusion, or they make assumptions that are not supported by the information given. For example, option 2 states that \"Socrates is a human, so he is definitely mortal\", but this is not a logical conclusion. It's a statement of fact, not a conclusion drawn from the premises. Similarly, option 4 states that \"Humans are mortal only if Socrates is too\", which is a false statement and not a logical conclusion from the premises.   Overall, this question assesses the candidate's ability to apply logical principles to arrive at a valid conclusion, and to distinguish between valid and invalid arguments. It requires critical thinking and the ability to analyze and evaluate arguments.  In a real-world scenario, this type of question could be relevant in fields such as law, philosophy, or critical thinking, where being able to evaluate and apply logical principles is crucial.   A candidate\n"
     ]
    }
   ],
   "source": [
    "model = QAgent()\n",
    "\n",
    "response = model.generate(\n",
    "    \"Generate one difficult syllogism MCQ in valid JSON format.\",\n",
    "    max_new_tokens=600\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d6bf694-49a3-41f5-b076-f7df03ee0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json(text):\n",
    "    try:\n",
    "        match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "        if match:\n",
    "            return json.loads(match.group())\n",
    "    except:\n",
    "        return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e141e00-e4a1-404d-925d-6f4f15aa7380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_sample(sample):\n",
    "    required_keys = [\"topic\", \"question\", \"choices\", \"answer\", \"explanation\"]\n",
    "\n",
    "    # Check structure\n",
    "    if not all(k in sample for k in required_keys):\n",
    "        return False\n",
    "\n",
    "    # Must have exactly 4 choices\n",
    "    if len(sample[\"choices\"]) != 4:\n",
    "        return False\n",
    "\n",
    "    # Question must end with ?\n",
    "    if not sample[\"question\"].strip().endswith(\"?\"):\n",
    "        return False\n",
    "\n",
    "    # No permutation counting\n",
    "    if \"permutation\" in sample[\"question\"].lower():\n",
    "        return False\n",
    "\n",
    "    # Only one answer letter\n",
    "    if sample[\"answer\"] not in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "630bf8eb-b96e-4624-9b93-95f66acab3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATION_INSTRUCTION = \"\"\"\n",
    "Generate one difficult logical reasoning MCQ.\n",
    "\n",
    "Allowed topics:\n",
    "- Syllogism\n",
    "- Seating Arrangement (Circular or Linear, no permutation counting)\n",
    "- Blood Relations\n",
    "- Mixed Alphanumeric Series\n",
    "\n",
    "Return ONLY valid JSON in this format:\n",
    "\n",
    "{\n",
    "    \"topic\": \"...\",\n",
    "    \"question\": \"...?\",\n",
    "    \"choices\": [\"A) ...\", \"B) ...\", \"C) ...\", \"D) ...\"],\n",
    "    \"answer\": \"A/B/C/D\",\n",
    "    \"explanation\": \"Brief explanation\"\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Multi-step reasoning required\n",
    "- Only one correct answer\n",
    "- No ambiguity\n",
    "- No extra commentary outside JSON\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1404a6c-a121-4dab-b983-c9fd10c20cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(model, target_size=1000):\n",
    "    dataset = []\n",
    "    attempts = 0\n",
    "    max_attempts = target_size * 3  # allow retries\n",
    "\n",
    "    while len(dataset) < target_size and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        \n",
    "        response = model.generate(GENERATION_INSTRUCTION, max_new_tokens=700)\n",
    "        sample = extract_json(response)\n",
    "\n",
    "        if sample and validate_sample(sample):\n",
    "            dataset.append(sample)\n",
    "            print(f\"âœ… {len(dataset)}/{target_size} valid\")\n",
    "        else:\n",
    "            print(f\"âŒ Invalid sample (attempt {attempts})\")\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "27ee1146-9658-4d03-adf2-b0352bd2b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(dataset, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for item in dataset:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "    print(f\"ðŸ’¾ Saved {len(dataset)} samples to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6eef1b17-d59b-4c46-93c8-01cb07b87d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-14 12:31:22] INFO modeling.py:987: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: AMD currently is not stable with 4bit bitsandbytes. Disabling for now.\n",
      "==((====))==  Unsloth 2025.10.9: Fast Llama patching. Transformers: 4.56.2. vLLM: 0.11.1rc3.dev39+gf417746ad.rocm700.\n",
      "   \\\\   /|    . Num GPUs = 1. Max memory: 255.688 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0a0+git1c57644. ROCm Toolkit: 7.0.51831-a3e329ad8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd57f51714524ab2a0e5905cd2ebdfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… QAgent loaded successfully\n",
      "âŒ Invalid sample (attempt 1)\n",
      "âœ… 1/20 valid\n",
      "âŒ Invalid sample (attempt 3)\n",
      "âŒ Invalid sample (attempt 4)\n",
      "âœ… 2/20 valid\n",
      "âŒ Invalid sample (attempt 6)\n",
      "âŒ Invalid sample (attempt 7)\n",
      "âŒ Invalid sample (attempt 8)\n",
      "âŒ Invalid sample (attempt 9)\n",
      "âŒ Invalid sample (attempt 10)\n",
      "âŒ Invalid sample (attempt 11)\n",
      "âŒ Invalid sample (attempt 12)\n",
      "âœ… 3/20 valid\n",
      "âœ… 4/20 valid\n",
      "âœ… 5/20 valid\n",
      "âŒ Invalid sample (attempt 16)\n",
      "âœ… 6/20 valid\n",
      "âŒ Invalid sample (attempt 18)\n",
      "âœ… 7/20 valid\n",
      "âœ… 8/20 valid\n",
      "âœ… 9/20 valid\n",
      "âŒ Invalid sample (attempt 22)\n",
      "âŒ Invalid sample (attempt 23)\n",
      "âŒ Invalid sample (attempt 24)\n",
      "âœ… 10/20 valid\n",
      "âŒ Invalid sample (attempt 26)\n",
      "âœ… 11/20 valid\n",
      "âŒ Invalid sample (attempt 28)\n",
      "âŒ Invalid sample (attempt 29)\n",
      "âŒ Invalid sample (attempt 30)\n",
      "âŒ Invalid sample (attempt 31)\n",
      "âœ… 12/20 valid\n",
      "âŒ Invalid sample (attempt 33)\n",
      "âŒ Invalid sample (attempt 34)\n",
      "âœ… 13/20 valid\n",
      "âŒ Invalid sample (attempt 36)\n",
      "âŒ Invalid sample (attempt 37)\n",
      "âŒ Invalid sample (attempt 38)\n",
      "âœ… 14/20 valid\n",
      "âŒ Invalid sample (attempt 40)\n",
      "âœ… 15/20 valid\n",
      "âœ… 16/20 valid\n",
      "âœ… 17/20 valid\n",
      "âŒ Invalid sample (attempt 44)\n",
      "âŒ Invalid sample (attempt 45)\n",
      "âœ… 18/20 valid\n",
      "âŒ Invalid sample (attempt 47)\n",
      "âŒ Invalid sample (attempt 48)\n",
      "âŒ Invalid sample (attempt 49)\n",
      "âœ… 19/20 valid\n",
      "âœ… 20/20 valid\n",
      "ðŸ’¾ Saved 20 samples to test_reasoning.jsonl\n"
     ]
    }
   ],
   "source": [
    "model = QAgent()\n",
    "\n",
    "dataset = generate_dataset(model, target_size=20)\n",
    "save_dataset(dataset, \"test_reasoning.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4589bdfd-65e3-4c8a-a947-9819dfae7b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "626a17df-ecf3-49ab-b759-0b189823bfdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find '/workspace/AAIPL/agents/AAIPL/agents/test_reasoning.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m      3\u001b[39m DATA_FILE = \u001b[33m\"\u001b[39m\u001b[33mAAIPL/agents/test_reasoning.jsonl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m dataset = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjson\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDATA_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat_example\u001b[39m(example):\n\u001b[32m      8\u001b[39m     choices_text = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(example[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/load.py:1397\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[39m\n\u001b[32m   1392\u001b[39m verification_mode = VerificationMode(\n\u001b[32m   1393\u001b[39m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode.BASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode.ALL_CHECKS\n\u001b[32m   1394\u001b[39m )\n\u001b[32m   1396\u001b[39m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1397\u001b[39m builder_instance = \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[32m   1413\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/load.py:1137\u001b[39m, in \u001b[36mload_dataset_builder\u001b[39m\u001b[34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, **config_kwargs)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1136\u001b[39m     features = _fix_for_backward_compatible_features(features)\n\u001b[32m-> \u001b[39m\u001b[32m1137\u001b[39m dataset_module = \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[38;5;66;03m# Get dataset builder class\u001b[39;00m\n\u001b[32m   1147\u001b[39m builder_kwargs = dataset_module.builder_kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/load.py:913\u001b[39m, in \u001b[36mdataset_module_factory\u001b[39m\u001b[34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[39m\n\u001b[32m    890\u001b[39m \u001b[38;5;66;03m# We have several ways to get a dataset builder:\u001b[39;00m\n\u001b[32m    891\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    892\u001b[39m \u001b[38;5;66;03m# - if path is the name of a packaged dataset module\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    904\u001b[39m \n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# Try packaged\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m _PACKAGED_DATASETS_MODULES:\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPackagedDatasetModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m913\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[38;5;66;03m# Try locally\u001b[39;00m\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m path.endswith(filename):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/load.py:527\u001b[39m, in \u001b[36mPackagedDatasetModuleFactory.get_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    521\u001b[39m base_path = Path(\u001b[38;5;28mself\u001b[39m.data_dir \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).expanduser().resolve().as_posix()\n\u001b[32m    522\u001b[39m patterns = (\n\u001b[32m    523\u001b[39m     sanitize_patterns(\u001b[38;5;28mself\u001b[39m.data_files)\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    525\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m get_data_patterns(base_path, download_config=\u001b[38;5;28mself\u001b[39m.download_config)\n\u001b[32m    526\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m data_files = \u001b[43mDataFilesDict\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m module_path, \u001b[38;5;28mhash\u001b[39m = _PACKAGED_DATASETS_MODULES[\u001b[38;5;28mself\u001b[39m.name]\n\u001b[32m    535\u001b[39m builder_kwargs = {\n\u001b[32m    536\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdata_files\u001b[39m\u001b[33m\"\u001b[39m: data_files,\n\u001b[32m    537\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdataset_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    538\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/data_files.py:701\u001b[39m, in \u001b[36mDataFilesDict.from_patterns\u001b[39m\u001b[34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[39m\n\u001b[32m    696\u001b[39m out = \u001b[38;5;28mcls\u001b[39m()\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, patterns_for_key \u001b[38;5;129;01min\u001b[39;00m patterns.items():\n\u001b[32m    698\u001b[39m     out[key] = (\n\u001b[32m    699\u001b[39m         patterns_for_key\n\u001b[32m    700\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mDataFilesList\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpatterns_for_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m            \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     )\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/data_files.py:594\u001b[39m, in \u001b[36mDataFilesList.from_patterns\u001b[39m\u001b[34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m patterns:\n\u001b[32m    592\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    593\u001b[39m         data_files.extend(\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m             \u001b[43mresolve_pattern\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m                \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m                \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m                \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m         )\n\u001b[32m    601\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m    602\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/data_files.py:383\u001b[39m, in \u001b[36mresolve_pattern\u001b[39m\u001b[34m(pattern, base_path, allowed_extensions, download_config)\u001b[39m\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    382\u001b[39m         error_msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m with any supported extension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(allowed_extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Unable to find '/workspace/AAIPL/agents/AAIPL/agents/test_reasoning.jsonl'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "DATA_FILE = \"AAIPL/agents/test_reasoning.jsonl\"\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=DATA_FILE, split=\"train\")\n",
    "\n",
    "def format_example(example):\n",
    "    choices_text = \"\\n\".join(example[\"choices\"])\n",
    "    \n",
    "    return {\n",
    "        \"text\": f\"\"\"### Instruction:\n",
    "Topic: {example[\"topic\"]}\n",
    "Generate one difficult logical reasoning MCQ.\n",
    "Do not provide explanation.\n",
    "Return only the question and 4 choices.\n",
    "\n",
    "### Response:\n",
    "{example[\"question\"]}\n",
    "\n",
    "{choices_text}\n",
    "\n",
    "Answer:\n",
    "{example[\"answer\"]}\"\"\"\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(format_example)\n",
    "\n",
    "print(\"Converted dataset size:\", len(dataset))\n",
    "print(dataset[0][\"text\"][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69351fc0-23a3-4b05-8622-512e1a366346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dcaeee-1407-4fa8-8734-9dca358d733a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b38fd134-989b-4a3a-a0f3-767274a61165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.9-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.5)\n",
      "Collecting pdfminer.six==20251230 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20251230-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (12.0.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-5.4.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (46.0.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.23)\n",
      "Downloading pdfplumber-0.11.9-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20251230-py3-none-any.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-5.4.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m228.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "\u001b[2K  Attempting uninstall: pdfminer.six\n",
      "\u001b[2K    Found existing installation: pdfminer.six 20250506\n",
      "\u001b[2K    Uninstalling pdfminer.six-20250506:\n",
      "\u001b[2K      Successfully uninstalled pdfminer.six-20250506\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/3\u001b[0m [pdfplumber]3\u001b[0m [pdfminer.six]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pdfminer.six-20251230 pdfplumber-0.11.9 pypdfium2-5.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.12 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9a11cb56-fa27-4b5b-aee9-687934e07ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.smartkeeda.com/pdf/N/Blood_Relation_PDF_Set_1.pdf\n",
      "âœ… Extracted 143 answers\n",
      "âœ… Extracted explanations for 27 questions\n",
      "âœ… Extracted 46 questions\n",
      "âœ… Final mapped dataset size: 46\n",
      "â¬‡ï¸ Downloading https://www.smartkeeda.com/pdf/N/Blood_Relation_PDF_Set_2.pdf\n",
      "âœ… Extracted 116 answers\n",
      "âœ… Extracted explanations for 0 questions\n",
      "âœ… Extracted 49 questions\n",
      "âœ… Final mapped dataset size: 49\n",
      "\n",
      "ðŸŽ¯ TOTAL QUESTIONS COLLECTED: 95\n",
      "ðŸ’¾ Saved to blood_relation_final_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pdfplumber\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "PDF_URLS = [\n",
    "    \"https://www.smartkeeda.com/pdf/N/Blood_Relation_PDF_Set_1.pdf\",\n",
    "    \"https://www.smartkeeda.com/pdf/N/Blood_Relation_PDF_Set_2.pdf\"\n",
    "]\n",
    "\n",
    "OUTPUT_FILE = \"blood_relation_final_dataset.jsonl\"\n",
    "\n",
    "# -------------------------------------------------\n",
    "# STEP 1: Download PDF\n",
    "# -------------------------------------------------\n",
    "def download_pdf(url, filename):\n",
    "    print(f\"â¬‡ï¸ Downloading {url}\")\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    return filename\n",
    "\n",
    "# -------------------------------------------------\n",
    "# STEP 2: Extract Text\n",
    "# -------------------------------------------------\n",
    "def extract_text(pdf_path):\n",
    "    full_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                full_text += text + \"\\n\"\n",
    "    return full_text\n",
    "\n",
    "# -------------------------------------------------\n",
    "# STEP 3: Extract Answer Grid\n",
    "# -------------------------------------------------\n",
    "def extract_answers(text):\n",
    "    answer_block = re.search(r\"CORRECT ANSWERS:(.*)\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if not answer_block:\n",
    "        print(\"âŒ Answer block not found\")\n",
    "        return {}\n",
    "\n",
    "    answer_text = answer_block.group(1)\n",
    "    answers = re.findall(r\"\\b[A-E]\\b\", answer_text)\n",
    "\n",
    "    answer_map = {}\n",
    "    for i, ans in enumerate(answers, start=1):\n",
    "        answer_map[i] = ans\n",
    "\n",
    "    print(f\"âœ… Extracted {len(answer_map)} answers\")\n",
    "    return answer_map\n",
    "\n",
    "# -------------------------------------------------\n",
    "# STEP 4: Extract Explanation Blocks\n",
    "# Handles: Common Explanation : [Q1 to Q3]\n",
    "# -------------------------------------------------\n",
    "def extract_explanations(text):\n",
    "    explanation_map = {}\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"Common Explanation\\s*:\\s*\\[Q?(\\d+)\\s*to\\s*Q?(\\d+)\\](.*?)(?=\\n\\d+[\\.\\)]|\\Z)\",\n",
    "        re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    matches = pattern.findall(text)\n",
    "\n",
    "    for start, end, explanation in matches:\n",
    "        for q_num in range(int(start), int(end) + 1):\n",
    "            explanation_map[q_num] = explanation.strip()\n",
    "\n",
    "    print(f\"âœ… Extracted explanations for {len(explanation_map)} questions\")\n",
    "    return explanation_map\n",
    "\n",
    "# -------------------------------------------------\n",
    "# STEP 5: Split Merged Options\n",
    "# Example: A. Mother B. Father C. Uncle ...\n",
    "# -------------------------------------------------\n",
    "def split_options(line):\n",
    "    options = re.findall(r\"[A-E][\\.\\)]\\s*[^A-E]+(?=\\s+[A-E][\\.\\)]|\\Z)\", line)\n",
    "    return [opt.strip() for opt in options]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# STEP 6: Extract Questions + Options\n",
    "# -------------------------------------------------\n",
    "def extract_questions(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    data = []\n",
    "\n",
    "    current_question = None\n",
    "    current_choices = []\n",
    "    current_number = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Detect question start (1. or 1))\n",
    "        q_match = re.match(r\"^(\\d+)[\\.\\)]\\s*(.*)\", line)\n",
    "        if q_match:\n",
    "            if current_question and current_choices:\n",
    "                data.append({\n",
    "                    \"number\": current_number,\n",
    "                    \"question\": current_question.strip(),\n",
    "                    \"choices\": current_choices\n",
    "                })\n",
    "\n",
    "            current_number = int(q_match.group(1))\n",
    "            current_question = q_match.group(2)\n",
    "            current_choices = []\n",
    "            continue\n",
    "\n",
    "        # Detect options (even if merged in one line)\n",
    "        if re.search(r\"[A-E][\\.\\)]\", line) and current_question:\n",
    "            current_choices = split_options(line)\n",
    "            continue\n",
    "\n",
    "        # Append multiline question content\n",
    "        if current_question and not current_choices:\n",
    "            current_question += \" \" + line\n",
    "\n",
    "    # Add last question\n",
    "    if current_question and current_choices:\n",
    "        data.append({\n",
    "            \"number\": current_number,\n",
    "            \"question\": current_question.strip(),\n",
    "            \"choices\": current_choices\n",
    "        })\n",
    "\n",
    "    print(f\"âœ… Extracted {len(data)} questions\")\n",
    "    return data\n",
    "\n",
    "# -------------------------------------------------\n",
    "# STEP 7: Merge Everything\n",
    "# -------------------------------------------------\n",
    "def merge_data(questions, answer_map, explanation_map):\n",
    "    final_data = []\n",
    "\n",
    "    for q in questions:\n",
    "        q_num = q[\"number\"]\n",
    "\n",
    "        if q_num in answer_map:\n",
    "            final_data.append({\n",
    "                \"topic\": \"Blood Relations\",\n",
    "                \"question\": q[\"question\"],\n",
    "                \"choices\": q[\"choices\"],\n",
    "                \"answer\": answer_map[q_num],\n",
    "                \"explanation\": explanation_map.get(q_num, \"\")\n",
    "            })\n",
    "\n",
    "    print(f\"âœ… Final mapped dataset size: {len(final_data)}\")\n",
    "    return final_data\n",
    "\n",
    "# -------------------------------------------------\n",
    "# STEP 8: Save JSONL\n",
    "# -------------------------------------------------\n",
    "def save_jsonl(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "    print(f\"ðŸ’¾ Saved to {filename}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# MAIN PIPELINE\n",
    "# -------------------------------------------------\n",
    "def main():\n",
    "    combined_dataset = []\n",
    "\n",
    "    for idx, url in enumerate(PDF_URLS):\n",
    "        pdf_filename = f\"temp_{idx}.pdf\"\n",
    "\n",
    "        download_pdf(url, pdf_filename)\n",
    "        text = extract_text(pdf_filename)\n",
    "\n",
    "        answer_map = extract_answers(text)\n",
    "        explanation_map = extract_explanations(text)\n",
    "        questions = extract_questions(text)\n",
    "\n",
    "        final_data = merge_data(questions, answer_map, explanation_map)\n",
    "\n",
    "        combined_dataset.extend(final_data)\n",
    "\n",
    "        os.remove(pdf_filename)\n",
    "\n",
    "    print(f\"\\nðŸŽ¯ TOTAL QUESTIONS COLLECTED: {len(combined_dataset)}\")\n",
    "    save_jsonl(combined_dataset, OUTPUT_FILE)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6e878f35-f0c2-44bb-ac04-fe315a9cd76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdf2image\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (12.0.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract, pdf2image\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [pdf2image]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pdf2image-1.17.0 pytesseract-0.3.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.12 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdf2image pytesseract pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8da95904-f521-47a9-a46f-956ca2140e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://repo.radeon.com/amdgpu/7.0/ubuntu jammy InRelease [3183 B]\n",
      "Get:2 https://repo.radeon.com/rocm/apt/7.0 jammy InRelease [2603 B]            \u001b[0m\u001b[33m\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]                \u001b[0m\n",
      "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \u001b[0m\u001b[33m\n",
      "Get:5 https://repo.radeon.com/amdgpu/7.0/ubuntu jammy/main amd64 Packages [1329 B]m\u001b[33m\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \u001b[0m\u001b[33m\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]      \u001b[0m\u001b[33m\n",
      "Get:8 https://repo.radeon.com/rocm/apt/7.0 jammy/main amd64 Packages [82.7 kB] \u001b[0m\u001b[33m\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1792 kB]     \u001b[0m\u001b[33m\n",
      "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]m\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB][0m\u001b[33m\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [70.9 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1611 kB]m\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [4047 kB]\u001b[33m\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6688 kB]\n",
      "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1299 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]33m\n",
      "Get:21 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [39.2 kB]\n",
      "Get:22 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [62.6 kB]\n",
      "Get:23 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6468 kB]\n",
      "Get:24 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3708 kB]\n",
      "Fetched 44.6 MB in 2s (25.7 MB/s)[33m                       \u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "64 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[1;33mW: \u001b[0mhttps://repo.radeon.com/amdgpu/7.0/ubuntu/dists/jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mhttps://repo.radeon.com/rocm/apt/7.0/dists/jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  fontconfig-config fonts-dejavu-core libcairo2 libdeflate0 libfontconfig1\n",
      "  libfreetype6 libjbig0 libjpeg-turbo8 libjpeg8 liblcms2-2 libnspr4 libnss3\n",
      "  libopenjp2-7 libpixman-1-0 libpng16-16 libpoppler118 libtiff5 libwebp7\n",
      "  libxcb-render0 libxrender1 poppler-data\n",
      "Suggested packages:\n",
      "  liblcms2-utils ghostscript fonts-japanese-mincho | fonts-ipafont-mincho\n",
      "  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n",
      "  fonts-arphic-uming fonts-nanum\n",
      "The following NEW packages will be installed:\n",
      "  fontconfig-config fonts-dejavu-core libcairo2 libdeflate0 libfontconfig1\n",
      "  libfreetype6 libjbig0 libjpeg-turbo8 libjpeg8 liblcms2-2 libnspr4 libnss3\n",
      "  libopenjp2-7 libpixman-1-0 libpng16-16 libpoppler118 libtiff5 libwebp7\n",
      "  libxcb-render0 libxrender1 poppler-data poppler-utils\n",
      "0 upgraded, 22 newly installed, 0 to remove and 64 not upgraded.\n",
      "Need to get 8556 kB of archives.\n",
      "After this operation, 31.9 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2171 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpng16-16 amd64 1.6.37-3ubuntu0.4 [192 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1041 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 fontconfig-config all 2.13.1-4.2ubuntu5 [29.1 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libfreetype6 amd64 2.11.1+dfsg-1ubuntu0.3 [388 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontconfig1 amd64 2.13.1-4.2ubuntu5 [131 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpixman-1-0 amd64 0.40.0-1ubuntu0.22.04.1 [264 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render0 amd64 1.14-3ubuntu3 [16.4 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxrender1 amd64 1:0.9.10-1build4 [19.7 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libcairo2 amd64 1.16.0-5ubuntu2 [628 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdeflate0 amd64 1.10-2 [70.9 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjpeg-turbo8 amd64 2.1.2-0ubuntu1 [134 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjpeg8 amd64 8c-2ubuntu10 [2264 B]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblcms2-2 amd64 2.12~rc1-2build2 [159 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnspr4 amd64 2:4.35-0ubuntu0.22.04.1 [119 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnss3 amd64 2:3.98-0ubuntu0.22.04.2 [1347 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libopenjp2-7 amd64 2.4.0-6ubuntu0.4 [158 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjbig0 amd64 2.1-3.1ubuntu0.22.04.1 [29.2 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libwebp7 amd64 1.2.2-2ubuntu0.22.04.2 [206 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtiff5 amd64 4.3.0-6ubuntu0.12 [185 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.12 [1079 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.12 [186 kB]\n",
      "Fetched 8556 kB in 1s (6564 kB/s)       \u001b[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package poppler-data.\n",
      "(Reading database ... 57133 files and directories currently installed.)\n",
      "Preparing to unpack .../00-poppler-data_0.4.11-1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  1%]\u001b[49m\u001b[39m [..........................................................] \u001b8Unpacking poppler-data (0.4.11-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Selecting previously unselected package libpng16-16:amd64.\n",
      "Preparing to unpack .../01-libpng16-16_1.6.37-3ubuntu0.4_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking libpng16-16:amd64 (1.6.37-3ubuntu0.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../02-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Selecting previously unselected package fontconfig-config.\n",
      "Preparing to unpack .../03-fontconfig-config_2.13.1-4.2ubuntu5_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking fontconfig-config (2.13.1-4.2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  9%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Selecting previously unselected package libfreetype6:amd64.\n",
      "Preparing to unpack .../04-libfreetype6_2.11.1+dfsg-1ubuntu0.3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Unpacking libfreetype6:amd64 (2.11.1+dfsg-1ubuntu0.3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package libfontconfig1:amd64.\n",
      "Preparing to unpack .../05-libfontconfig1_2.13.1-4.2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Unpacking libfontconfig1:amd64 (2.13.1-4.2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Selecting previously unselected package libpixman-1-0:amd64.\n",
      "Preparing to unpack .../06-libpixman-1-0_0.40.0-1ubuntu0.22.04.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 15%]\u001b[49m\u001b[39m [########..................................................] \u001b8Unpacking libpixman-1-0:amd64 (0.40.0-1ubuntu0.22.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Selecting previously unselected package libxcb-render0:amd64.\n",
      "Preparing to unpack .../07-libxcb-render0_1.14-3ubuntu3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking libxcb-render0:amd64 (1.14-3ubuntu3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Selecting previously unselected package libxrender1:amd64.\n",
      "Preparing to unpack .../08-libxrender1_1%3a0.9.10-1build4_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking libxrender1:amd64 (1:0.9.10-1build4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Selecting previously unselected package libcairo2:amd64.\n",
      "Preparing to unpack .../09-libcairo2_1.16.0-5ubuntu2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [############..............................................] \u001b8Unpacking libcairo2:amd64 (1.16.0-5ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package libdeflate0:amd64.\n",
      "Preparing to unpack .../10-libdeflate0_1.10-2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking libdeflate0:amd64 (1.10-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8Selecting previously unselected package libjpeg-turbo8:amd64.\n",
      "Preparing to unpack .../11-libjpeg-turbo8_2.1.2-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking libjpeg-turbo8:amd64 (2.1.2-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 27%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Selecting previously unselected package libjpeg8:amd64.\n",
      "Preparing to unpack .../12-libjpeg8_8c-2ubuntu10_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Unpacking libjpeg8:amd64 (8c-2ubuntu10) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [################..........................................] \u001b8Selecting previously unselected package liblcms2-2:amd64.\n",
      "Preparing to unpack .../13-liblcms2-2_2.12~rc1-2build2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 30%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking liblcms2-2:amd64 (2.12~rc1-2build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8Selecting previously unselected package libnspr4:amd64.\n",
      "Preparing to unpack .../14-libnspr4_2%3a4.35-0ubuntu0.22.04.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [##################........................................] \u001b8Unpacking libnspr4:amd64 (2:4.35-0ubuntu0.22.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 34%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Selecting previously unselected package libnss3:amd64.\n",
      "Preparing to unpack .../15-libnss3_2%3a3.98-0ubuntu0.22.04.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Unpacking libnss3:amd64 (2:3.98-0ubuntu0.22.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package libopenjp2-7:amd64.\n",
      "Preparing to unpack .../16-libopenjp2-7_2.4.0-6ubuntu0.4_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 37%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Unpacking libopenjp2-7:amd64 (2.4.0-6ubuntu0.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Selecting previously unselected package libjbig0:amd64.\n",
      "Preparing to unpack .../17-libjbig0_2.1-3.1ubuntu0.22.04.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 39%]\u001b[49m\u001b[39m [######################....................................] \u001b8Unpacking libjbig0:amd64 (2.1-3.1ubuntu0.22.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package libwebp7:amd64.\n",
      "Preparing to unpack .../18-libwebp7_1.2.2-2ubuntu0.22.04.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 42%]\u001b[49m\u001b[39m [########################..................................] \u001b8Unpacking libwebp7:amd64 (1.2.2-2ubuntu0.22.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [########################..................................] \u001b8Selecting previously unselected package libtiff5:amd64.\n",
      "Preparing to unpack .../19-libtiff5_4.3.0-6ubuntu0.12_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Unpacking libtiff5:amd64 (4.3.0-6ubuntu0.12) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8Selecting previously unselected package libpoppler118:amd64.\n",
      "Preparing to unpack .../20-libpoppler118_22.02.0-2ubuntu0.12_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Unpacking libpoppler118:amd64 (22.02.0-2ubuntu0.12) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Selecting previously unselected package poppler-utils.\n",
      "Preparing to unpack .../21-poppler-utils_22.02.0-2ubuntu0.12_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [############################..............................] \u001b8Unpacking poppler-utils (22.02.0-2ubuntu0.12) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 49%]\u001b[49m\u001b[39m [############################..............................] \u001b8Setting up liblcms2-2:amd64 (2.12~rc1-2build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Setting up libpixman-1-0:amd64 (0.40.0-1ubuntu0.22.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 53%]\u001b[49m\u001b[39m [##############################............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Setting up libxrender1:amd64 (1:0.9.10-1build4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [###############################...........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8Setting up libxcb-render0:amd64 (1.14-3ubuntu3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [#################################.........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 58%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up libdeflate0:amd64 (1.10-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 61%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up libjbig0:amd64 (2.1-3.1ubuntu0.22.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [###################################.......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 63%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up poppler-data (0.4.11-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up libnspr4:amd64 (2:4.35-0ubuntu0.22.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up libpng16-16:amd64 (1.6.37-3ubuntu0.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [#######################################...................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 70%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up fonts-dejavu-core (2.37-2build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 72%]\u001b[49m\u001b[39m [#########################################.................] \u001b8Setting up libjpeg-turbo8:amd64 (2.1.2-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 73%]\u001b[49m\u001b[39m [##########################################................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Setting up libwebp7:amd64 (1.2.2-2ubuntu0.22.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up libopenjp2-7:amd64 (2.4.0-6ubuntu0.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [############################################..............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [#############################################.............] \u001b8Setting up libjpeg8:amd64 (8c-2ubuntu10) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [##############################################............] \u001b8Setting up fontconfig-config (2.13.1-4.2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up libnss3:amd64 (2:3.98-0ubuntu0.22.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8Setting up libfreetype6:amd64 (2.11.1+dfsg-1ubuntu0.3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [##################################################........] \u001b8Setting up libtiff5:amd64 (4.3.0-6ubuntu0.12) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up libfontconfig1:amd64 (2.13.1-4.2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 91%]\u001b[49m\u001b[39m [####################################################......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Setting up libcairo2:amd64 (1.16.0-5ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [######################################################....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Setting up libpoppler118:amd64 (22.02.0-2ubuntu0.12) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 96%]\u001b[49m\u001b[39m [#######################################################...] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8Setting up poppler-utils (22.02.0-2ubuntu0.12) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [########################################################..] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 99%]\u001b[49m\u001b[39m [#########################################################.] \u001b8Processing triggers for libc-bin (2.35-0ubuntu3.10) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!apt update\n",
    "!apt install -y poppler-utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d9f3ea18-14bf-4674-92a2-1e139f6c02a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  fontconfig libdatrie1 libfribidi0 libgif7 libgraphite2-3 libharfbuzz0b\n",
      "  liblept5 libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libtesseract4\n",
      "  libthai-data libthai0 libwebpmux3 tesseract-ocr-eng tesseract-ocr-osd\n",
      "The following NEW packages will be installed:\n",
      "  fontconfig libdatrie1 libfribidi0 libgif7 libgraphite2-3 libharfbuzz0b\n",
      "  liblept5 libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libtesseract4\n",
      "  libthai-data libthai0 libwebpmux3 tesseract-ocr tesseract-ocr-eng\n",
      "  tesseract-ocr-osd\n",
      "0 upgraded, 17 newly installed, 0 to remove and 64 not upgraded.\n",
      "Need to get 8437 kB of archives.\n",
      "After this operation, 25.2 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libfribidi0 amd64 1.0.8-2ubuntu3.1 [26.1 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fontconfig amd64 2.13.1-4.2ubuntu5 [177 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdatrie1 amd64 0.2.13-2 [19.9 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgif7 amd64 5.1.9-2ubuntu0.1 [33.9 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgraphite2-3 amd64 1.3.14-1build2 [71.3 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libharfbuzz0b amd64 2.7.4-1ubuntu3.2 [353 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libwebpmux3 amd64 1.2.2-2ubuntu0.22.04.2 [20.5 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblept5 amd64 1.82.0-3build1 [1107 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libthai-data all 0.1.29-1build1 [162 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libthai0 amd64 0.1.29-1build1 [19.2 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpango-1.0-0 amd64 1.50.6+ds-2ubuntu1 [230 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpangoft2-1.0-0 amd64 1.50.6+ds-2ubuntu1 [54.0 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpangocairo-1.0-0 amd64 1.50.6+ds-2ubuntu1 [39.8 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract4 amd64 4.1.1-2.1build1 [1308 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1591 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2990 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
      "Fetched 8437 kB in 1s (6971 kB/s)      \u001b[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libfribidi0:amd64.\n",
      "(Reading database ... 57925 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libfribidi0_1.0.8-2ubuntu3.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  1%]\u001b[49m\u001b[39m [..........................................................] \u001b8Unpacking libfribidi0:amd64 (1.0.8-2ubuntu3.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Selecting previously unselected package fontconfig.\n",
      "Preparing to unpack .../01-fontconfig_2.13.1-4.2ubuntu5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8Unpacking fontconfig (2.13.1-4.2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Selecting previously unselected package libdatrie1:amd64.\n",
      "Preparing to unpack .../02-libdatrie1_0.2.13-2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking libdatrie1:amd64 (0.2.13-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  9%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Selecting previously unselected package libgif7:amd64.\n",
      "Preparing to unpack .../03-libgif7_5.1.9-2ubuntu0.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Unpacking libgif7:amd64 (5.1.9-2ubuntu0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package libgraphite2-3:amd64.\n",
      "Preparing to unpack .../04-libgraphite2-3_1.3.14-1build2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Unpacking libgraphite2-3:amd64 (1.3.14-1build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package libharfbuzz0b:amd64.\n",
      "Preparing to unpack .../05-libharfbuzz0b_2.7.4-1ubuntu3.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking libharfbuzz0b:amd64 (2.7.4-1ubuntu3.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [##########................................................] \u001b8Selecting previously unselected package libwebpmux3:amd64.\n",
      "Preparing to unpack .../06-libwebpmux3_1.2.2-2ubuntu0.22.04.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [##########................................................] \u001b8Unpacking libwebpmux3:amd64 (1.2.2-2ubuntu0.22.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Selecting previously unselected package liblept5:amd64.\n",
      "Preparing to unpack .../07-liblept5_1.82.0-3build1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Unpacking liblept5:amd64 (1.82.0-3build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package libthai-data.\n",
      "Preparing to unpack .../08-libthai-data_0.1.29-1build1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking libthai-data (0.1.29-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Selecting previously unselected package libthai0:amd64.\n",
      "Preparing to unpack .../09-libthai0_0.1.29-1build1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Unpacking libthai0:amd64 (0.1.29-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [################..........................................] \u001b8Selecting previously unselected package libpango-1.0-0:amd64.\n",
      "Preparing to unpack .../10-libpango-1.0-0_1.50.6+ds-2ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 30%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking libpango-1.0-0:amd64 (1.50.6+ds-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 32%]\u001b[49m\u001b[39m [##################........................................] \u001b8Selecting previously unselected package libpangoft2-1.0-0:amd64.\n",
      "Preparing to unpack .../11-libpangoft2-1.0-0_1.50.6+ds-2ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking libpangoft2-1.0-0:amd64 (1.50.6+ds-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package libpangocairo-1.0-0:amd64.\n",
      "Preparing to unpack .../12-libpangocairo-1.0-0_1.50.6+ds-2ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Unpacking libpangocairo-1.0-0:amd64 (1.50.6+ds-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Selecting previously unselected package libtesseract4:amd64.\n",
      "Preparing to unpack .../13-libtesseract4_4.1.1-2.1build1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 39%]\u001b[49m\u001b[39m [######################....................................] \u001b8Unpacking libtesseract4:amd64 (4.1.1-2.1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package tesseract-ocr-eng.\n",
      "Preparing to unpack .../14-tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 42%]\u001b[49m\u001b[39m [########################..................................] \u001b8Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Selecting previously unselected package tesseract-ocr-osd.\n",
      "Preparing to unpack .../15-tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Selecting previously unselected package tesseract-ocr.\n",
      "Preparing to unpack .../16-tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 49%]\u001b[49m\u001b[39m [############################..............................] \u001b8Setting up libgraphite2-3:amd64 (1.3.14-1build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [##############################............................] \u001b8Setting up fontconfig (2.13.1-4.2ubuntu5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Regenerating fonts cache... done.\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Setting up libdatrie1:amd64 (0.2.13-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 58%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 61%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up libfribidi0:amd64 (1.0.8-2ubuntu3.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [####################################......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up libgif7:amd64 (5.1.9-2ubuntu0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up libharfbuzz0b:amd64 (2.7.4-1ubuntu3.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 70%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up libthai-data (0.1.29-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 72%]\u001b[49m\u001b[39m [##########################################................] \u001b8Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [##########################################................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Setting up libwebpmux3:amd64 (1.2.2-2ubuntu0.22.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8Setting up liblept5:amd64 (1.82.0-3build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up libthai0:amd64 (0.1.29-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [###############################################...........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up libtesseract4:amd64 (4.1.1-2.1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [#################################################.........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8Setting up libpango-1.0-0:amd64 (1.50.6+ds-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up libpangoft2-1.0-0:amd64 (1.50.6+ds-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 91%]\u001b[49m\u001b[39m [####################################################......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Setting up libpangocairo-1.0-0:amd64 (1.50.6+ds-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 96%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 99%]\u001b[49m\u001b[39m [#########################################################.] \u001b8Processing triggers for libc-bin (2.35-0ubuntu3.10) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!apt install -y tesseract-ocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "814a53a4-d530-4624-9539-7d57cb19c1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in /usr/local/lib/python3.12/dist-packages (1.17.0)\n",
      "Requirement already satisfied: pytesseract in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (12.0.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.12 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image pytesseract pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c8557519-395f-4719-8512-ba5a2c6dca7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Converting PDF to images...\n",
      "OCR page 1\n",
      "OCR page 2\n",
      "OCR page 3\n",
      "OCR page 4\n",
      "OCR page 5\n",
      "OCR page 6\n",
      "OCR page 7\n",
      "OCR page 8\n",
      "OCR page 9\n",
      "OCR page 10\n",
      "OCR page 11\n",
      "OCR page 12\n",
      "OCR page 13\n",
      "âœ… OCR extraction complete\n",
      "\n",
      "First 500 characters:\n",
      "\n",
      "BLOOD RELATIONS\n",
      "\n",
      "19\n",
      "\n",
      "ea a\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "DEFINITION\n",
      "\n",
      "Those persons who are related to another persons by birth rather than by marriage\n",
      "are called in Blood Relation.\n",
      "\n",
      "Letâ€™s start right from basic and see what are the different blood relations in a family,\n",
      "which we should know to understand the logical reasoning in blood relation\n",
      "questions.\n",
      "\n",
      "Remember the relations as given below:\n",
      "\n",
      "(i) Children of Same parents | â€”>+ Siblings\n",
      "Oneâ€™s Husband or Wife â€”> Spouse\n",
      "Relatives on Motherâ€™s Side â€”Â» Maternal\n",
      "Relatives o\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import os\n",
    "\n",
    "PDF_PATH = \"book_sample.pdf\"  # make sure file exists\n",
    "OUTPUT_FILE = \"ocr_output.txt\"\n",
    "\n",
    "def extract_text_ocr(pdf_path):\n",
    "    print(\"ðŸ”„ Converting PDF to images...\")\n",
    "    images = convert_from_path(pdf_path)\n",
    "\n",
    "    full_text = \"\"\n",
    "    for i, image in enumerate(images):\n",
    "        print(f\"OCR page {i+1}\")\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        full_text += text + \"\\n\"\n",
    "\n",
    "    return full_text\n",
    "\n",
    "text = extract_text_ocr(PDF_PATH)\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"âœ… OCR extraction complete\")\n",
    "print(\"\\nFirst 500 characters:\\n\")\n",
    "print(text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f752710f-e682-4289-ab55-f173e69f14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Agent (Production Version)\n",
    "import time\n",
    "import torch\n",
    "from typing import Optional, List\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "# ðŸ”¹ CHANGE THESE PATHS IF NEEDED\n",
    "BASE_MODEL_PATH = \"/workspace/AAIPL/hf_models/huggingface/models--Qwen--Qwen2.5-14B-Instruct/snapshots/cf98f3b3bbb457ad9e2bb7baf9a0125b6b88caa8\"\n",
    "Q_LORA_PATH = \"/workspace/AAIPL/qwen14b_lora\"   # Your fine-tuned Q-agent weights\n",
    "\n",
    "class QAgent(object):\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        # ---------------- TOKENIZER ----------------\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            BASE_MODEL_PATH,\n",
    "            padding_side=\"left\",\n",
    "            local_files_only=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "\n",
    "        # ---------------- BASE MODEL ----------------\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            BASE_MODEL_PATH,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16,\n",
    "            local_files_only=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        # ---------------- ATTACH FINETUNED LoRA ----------------\n",
    "        self.model = PeftModel.from_pretrained(\n",
    "            base_model,\n",
    "            Q_LORA_PATH,\n",
    "            is_trainable=False\n",
    "        )\n",
    "\n",
    "        self.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed64775e-848e-4b65-b2d7-0624b4f4b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Agent (Production Version)\n",
    "import time\n",
    "import torch\n",
    "from typing import Optional, List\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "# ðŸ”¹ CHANGE THESE PATHS IF NEEDED\n",
    "BASE_MODEL_PATH = \"/workspace/AAIPL/hf_models/huggingface/models--Qwen--Qwen2.5-14B-Instruct/snapshots/cf98f3b3bbb457ad9e2bb7baf9a0125b6b88caa8\"\n",
    "Q_LORA_PATH = \"/workspace/AAIPL/qwen14b_lora\"   # Your fine-tuned Q-agent weights\n",
    "\n",
    "class QAgent(object):\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        # ---------------- TOKENIZER ----------------\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            BASE_MODEL_PATH,\n",
    "            padding_side=\"left\",\n",
    "            local_files_only=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "\n",
    "        # ---------------- BASE MODEL ----------------\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            BASE_MODEL_PATH,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16,\n",
    "            local_files_only=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        # ---------------- ATTACH FINETUNED LoRA ----------------\n",
    "        self.model = PeftModel.from_pretrained(\n",
    "            base_model,\n",
    "            Q_LORA_PATH,\n",
    "            is_trainable=False\n",
    "        )\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "    def generate_response(\n",
    "        self,\n",
    "        message: str | List[str],\n",
    "        system_prompt: Optional[str] = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        if system_prompt is None:\n",
    "            system_prompt = \"You are a difficult reasoning question generator.\"\n",
    "\n",
    "        if isinstance(message, str):\n",
    "            message = [message]\n",
    "\n",
    "        # Prepare chat format\n",
    "        all_messages = []\n",
    "        for msg in message:\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": msg},\n",
    "            ]\n",
    "            all_messages.append(messages)\n",
    "\n",
    "        # Apply chat template\n",
    "        texts = []\n",
    "        for messages in all_messages:\n",
    "            text = self.tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True,\n",
    "            )\n",
    "            texts.append(text)\n",
    "\n",
    "        # Tokenize\n",
    "        model_inputs = self.tokenizer(\n",
    "            texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        tgps_show = kwargs.get(\"tgps_show\", False)\n",
    "\n",
    "        if tgps_show:\n",
    "            start_time = time.time()\n",
    "\n",
    "        generated_ids = self.model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=kwargs.get(\"max_new_tokens\", 512),\n",
    "            temperature=kwargs.get(\"temperature\", 0.7),\n",
    "            top_p=kwargs.get(\"top_p\", 0.9),\n",
    "            do_sample=kwargs.get(\"do_sample\", True),\n",
    "            pad_token_id=self.tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "        if tgps_show:\n",
    "            generation_time = time.time() - start_time\n",
    "\n",
    "        batch_outs = []\n",
    "        token_len = 0\n",
    "\n",
    "        for input_ids, generated_sequence in zip(model_inputs.input_ids, generated_ids):\n",
    "            output_ids = generated_sequence[len(input_ids):]\n",
    "            token_len += len(output_ids)\n",
    "\n",
    "            content = self.tokenizer.decode(\n",
    "                output_ids,\n",
    "                skip_special_tokens=True\n",
    "            ).strip()\n",
    "\n",
    "            batch_outs.append(content)\n",
    "\n",
    "        if tgps_show:\n",
    "            return (\n",
    "                batch_outs[0] if len(batch_outs) == 1 else batch_outs,\n",
    "                token_len,\n",
    "                generation_time\n",
    "            )\n",
    "\n",
    "        return batch_outs[0] if len(batch_outs) == 1 else batch_outs, None, None\n",
    "\n",
    "\n",
    "# ---------------- TEST BLOCK ----------------\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    q_agent = QAgent()\n",
    "\n",
    "    response, tl, gt = q_agent.generate_response(\n",
    "        \"\"\"\n",
    "        Generate a difficult Blood Relation MCQ question.\n",
    "        Return valid JSON with topic, question, choices, answer and explanation.\n",
    "        \"\"\",\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.8,\n",
    "        tgps_show=True\n",
    "    )\n",
    "\n",
    "    print(\"Response:\\n\", response)\n",
    "    print(f\"Tokens: {tl}, Time: {gt:.2f}s, TPS: {tl/gt:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ed5a6f2c-bbeb-430c-83e4-bf1dc2fd5449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-15 08:26:55] INFO modeling.py:987: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a545c58a31014704a2e3f8118357e903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {\"question\": \"What is the next number in the series: 1, 4, 9, 16, 25, ___?\", \"A\": \"30\", \"B\": \"35\", \"C\": \"36\", \"D\": \"40\"}\n",
      "Total tokens: 61, Time taken: 3.23 seconds, TGPS: 18.86\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from typing import Optional, List\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "BASE_MODEL_PATH = \"/workspace/AAIPL/hf_models/huggingface/models--Qwen--Qwen2.5-14B-Instruct/snapshots/cf98f3b3bbb457ad9e2bb7baf9a0125b6b88caa8\"\n",
    "Q_LORA_PATH = \"/workspace/AAIPL/qwen14b_lora\"\n",
    "\n",
    "\n",
    "class QAgent:\n",
    "    def __init__(self):\n",
    "\n",
    "        # ---------------- TOKENIZER ----------------\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            BASE_MODEL_PATH,\n",
    "            padding_side=\"left\",\n",
    "            local_files_only=True,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "\n",
    "        # ---------------- BASE MODEL ----------------\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            BASE_MODEL_PATH,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16,\n",
    "            local_files_only=True,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "\n",
    "        # ---------------- ATTACH LoRA ----------------\n",
    "        self.model = PeftModel.from_pretrained(\n",
    "            base_model,\n",
    "            Q_LORA_PATH,\n",
    "            is_trainable=False,\n",
    "        )\n",
    "\n",
    "        self.model.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "    # âœ… FIXED INDENTATION HERE\n",
    "    def generate_response(\n",
    "        self, message: str | List[str], system_prompt: Optional[str] = None, **kwargs\n",
    "    ):\n",
    "\n",
    "        if system_prompt is None:\n",
    "            system_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "        if isinstance(message, str):\n",
    "            message = [message]\n",
    "\n",
    "        all_messages = []\n",
    "        for msg in message:\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": msg},\n",
    "            ]\n",
    "            all_messages.append(messages)\n",
    "\n",
    "        texts = []\n",
    "        for messages in all_messages:\n",
    "            text = self.tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True,\n",
    "                enable_thinking=False,\n",
    "            )\n",
    "            texts.append(text)\n",
    "\n",
    "        model_inputs = self.tokenizer(\n",
    "            texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        tgps_show_var = kwargs.get(\"tgps_show\", False)\n",
    "\n",
    "        if tgps_show_var:\n",
    "            start_time = time.time()\n",
    "\n",
    "        generated_ids = self.model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=kwargs.get(\"max_new_tokens\", 1024),\n",
    "            pad_token_id=self.tokenizer.pad_token_id,\n",
    "            temperature=kwargs.get(\"temperature\", 0.7),\n",
    "            top_p=kwargs.get(\"top_p\", 0.9),\n",
    "            do_sample=kwargs.get(\"do_sample\", True),\n",
    "        )\n",
    "\n",
    "        if tgps_show_var:\n",
    "            generation_time = time.time() - start_time\n",
    "\n",
    "        batch_outs = []\n",
    "        token_len = 0\n",
    "\n",
    "        for input_ids, generated_sequence in zip(\n",
    "            model_inputs.input_ids, generated_ids\n",
    "        ):\n",
    "            output_ids = generated_sequence[len(input_ids):].tolist()\n",
    "\n",
    "            if tgps_show_var:\n",
    "                token_len += len(output_ids)\n",
    "\n",
    "            # remove thinking content if present\n",
    "            if 151668 in output_ids:\n",
    "                index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "            else:\n",
    "                index = 0\n",
    "\n",
    "            content = self.tokenizer.decode(\n",
    "                output_ids[index:], skip_special_tokens=True\n",
    "            ).strip(\"\\n\")\n",
    "\n",
    "            batch_outs.append(content)\n",
    "\n",
    "        if tgps_show_var:\n",
    "            return (\n",
    "                batch_outs[0] if len(batch_outs) == 1 else batch_outs,\n",
    "                token_len,\n",
    "                generation_time,\n",
    "            )\n",
    "\n",
    "        return batch_outs[0] if len(batch_outs) == 1 else batch_outs, None, None\n",
    "\n",
    "\n",
    "# ---------------- TEST ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    model = QAgent()\n",
    "\n",
    "    response, tl, tm = model.generate_response(\n",
    "        \"Generate a hard MCQ on Number Series in JSON format.\",\n",
    "        tgps_show=True,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.1,\n",
    "        top_p=0.9,\n",
    "        do_sample=True,\n",
    "    )\n",
    "\n",
    "    print(\"Response:\", response)\n",
    "    print(\n",
    "        f\"Total tokens: {tl}, Time taken: {tm:.2f} seconds, TGPS: {tl/tm:.2f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75120a00-9f43-4742-9c31-c1802c06d1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
